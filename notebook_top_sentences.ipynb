{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from questions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_MATCHES = 1\n",
    "SENTENCE_MATCHES = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = load_files(\"./corpus/\") # Load file into memory.\n",
    "file_words = {\n",
    "    filename: tokenize(files[filename]) # Tokenize into list of words.\n",
    "    for filename in files\n",
    "}\n",
    "file_idfs = compute_idfs(file_words) # Compute inverse document frequency values for each word.\n",
    "\n",
    "# Prompt user for query\n",
    "query = set(tokenize(\"When was machine learning founded?\"))\n",
    "\n",
    "# Determine top file matches according to TF-IDF\n",
    "filenames = top_files(query, file_words, file_idfs, n=FILE_MATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentences from top files\n",
    "sentences = dict()\n",
    "for filename in filenames:\n",
    "    for passage in files[filename].split(\"\\n\"):\n",
    "        for sentence in nltk.sent_tokenize(passage):\n",
    "            tokens = tokenize(sentence)\n",
    "            if tokens:\n",
    "                sentences[sentence] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = compute_idfs(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query: check\n",
    "# sentences: check\n",
    "# idfs: check\n",
    "# return: n top sentences ordered according IDF\n",
    "\n",
    "# Compute a sum of all words in one sentence. \n",
    "# Save this sum as key in dictionary.\n",
    "sentence_0 = sentences['In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for i in sentence_0:\n",
    "    sum += idfs[i]\n",
    "    \n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences = {}\n",
    "\n",
    "new_sentences['sentence'] = 66.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences = {}\n",
    "for sentence in sentences:\n",
    "    idf_sum = 0\n",
    "    for word in sentences[sentence]:\n",
    "        idf_sum += idfs[word]\n",
    "    # Map idf_sum with sentence to new dict new_sentences.\n",
    "    new_sentences[sentence] = idf_sum\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_sentences = {}\n",
    "for sentence in sentences:    \n",
    "    idf_sum = 0\n",
    "    # Loop over words in set query.\n",
    "    for word in query:\n",
    "        if word in sentences[sentence] and idfs[word] != 0:\n",
    "            idf_sum += idfs[word]\n",
    "\n",
    "    # Compute idf sum and map in dict.\n",
    "    idf_sentences[sentence] = idf_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "list_ordered_sentences = []\n",
    "sentences_idf_sorted = sorted(idf_sentences.items(), key= lambda x:x[1], reverse=True)\n",
    "\n",
    "i = 0\n",
    "while i < n:\n",
    "    list_ordered_sentences.append(sentences_idf_sorted[i][0])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ordered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_idf_sorted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_sentences_(query, sentences, idfs, n):\n",
    "    idf_sentences = {}\n",
    "    for sentence in sentences:    \n",
    "        idf_sum = 0\n",
    "        # Loop over words in set query.\n",
    "        for word in query:\n",
    "            if word in sentences[sentence] and idfs[word] != 0:\n",
    "                idf_sum += idfs[word]\n",
    "\n",
    "        # Compute idf sum and map in dict.\n",
    "        idf_sentences[sentence] = idf_sum\n",
    "    \n",
    "    # Order the sentences and return list with length n\n",
    "    list_ordered_sentences = []\n",
    "    sentences_idf_sorted = sorted(idf_sentences.items(), key= lambda x:x[1], reverse=True)\n",
    "\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        list_ordered_sentences.append(sentences_idf_sorted[i][0])\n",
    "        i += 1\n",
    "    \n",
    "    return list_ordered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_sentences_list = top_sentences_(query, sentences, idfs, 10)\n",
    "top_sentences_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentence_0)\n",
    "# count_densitiy...  if word of query in sentences[sentence] -> then count_density += 1\n",
    "# density = count_density / len(sentences[sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_sentences_2(query, sentences, idfs, n):\n",
    "    idf_sentences = {}\n",
    "    for sentence in sentences:    \n",
    "        idf_sum = 0\n",
    "        count_density = 0\n",
    "        # Loop over words in set query.\n",
    "        for word in query:\n",
    "            if word in sentences[sentence] and idfs[word] != 0:\n",
    "                idf_sum += idfs[word]\n",
    "                count_density += 1\n",
    "\n",
    "        # Compute idf sum and map in dict.\n",
    "        idf_sentences[sentence] = [idf_sum, count_density/len(sentences[sentence])]\n",
    "    \n",
    "    # Order the sentences and return list with length n\n",
    "    list_ordered_sentences = []\n",
    "    sentences_idf_sorted = sorted(idf_sentences.items(), key= lambda x:(x[1][0], x[1][1]), reverse=True)\n",
    "\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        list_ordered_sentences.append(sentences_idf_sorted[i][0])\n",
    "        i += 1\n",
    "    \n",
    "    return list_ordered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_sentences_list = top_sentences_2(query, sentences, idfs, 10)\n",
    "top_sentences_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51aac96a1ad50adc7d4a1a596256386b3ce94cd59070594d461c13d85ed1cee1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
