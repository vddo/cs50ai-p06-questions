{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from questions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = load_files(\"./corpus/\") # Load file into memory as string.\n",
    "file_words = {\n",
    "    filename: tokenize(files[filename]) # Tokenize into list of words.\n",
    "    for filename in files\n",
    "}\n",
    "file_idfs = compute_idfs(file_words) # Compute inverse document frequency values for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute number of times term appears in document.\n",
    "\n",
    "query = \"machine\"\n",
    "\n",
    "document_list_words = file_words[\"python.txt\"]\n",
    "\n",
    "num_in_doc = document_list_words.count(query)\n",
    "print(num_in_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2 = \"machine learning duc\"\n",
    "\n",
    "list_num_in_doc = []\n",
    "for word in query_2.split():\n",
    "    list_num_in_doc.append(document_list_words.count(word))\n",
    "    \n",
    "print(list_num_in_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ft-idf\n",
    "query_2 = \"machine learning duc compute python\"\n",
    "\n",
    "list_num_in_doc = []\n",
    "for word in query_2.split():\n",
    "    # list_num_in_doc.append(document_list_words.count(word))\n",
    "    if word in file_idfs:\n",
    "        # print(file_idfs[word])\n",
    "        if file_idfs[word] != 0:\n",
    "            list_num_in_doc.append(file_idfs[word] * document_list_words.count(word))\n",
    "            # print(\"count: \", document_list_words.count(word))\n",
    "    \n",
    "# print(list_num_in_doc)\n",
    "\n",
    "# Sum elements in list and save with file name.\n",
    "\n",
    "list_files_tfidf = {}\n",
    "list_files_tfidf[\"python.txt\"] = sum(list_num_in_doc)\n",
    "# list_files_tfidf.append([\"python.txt\", sum(list_num_in_doc)])\n",
    "print(list_files_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_tfidf = {\n",
    "    \"python\" : 123,\n",
    "    \"machine\" : 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(file_tfidf, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize query\n",
    "# questions.tokenize() will remove puncuations and stopwords. \n",
    "# Our data set is also free of both. Function can be used for query, too.\n",
    "query = \"When was python founded? Python is best!\"\n",
    "set_query = set(tokenize(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability.txt : ai 0.4054651081081644\n",
      "probability.txt : learning 0.0\n",
      "probability.txt : machine 0.0\n",
      "probability.txt : networks 0.6931471805599453\n",
      "probability.txt : neural 0.4054651081081644\n",
      "python.txt : ai 0.4054651081081644\n",
      "python.txt : learning 0.0\n",
      "python.txt : machine 0.0\n",
      "python.txt : networks 0.6931471805599453\n",
      "python.txt : neural 0.4054651081081644\n",
      "natural_language_processing.txt : ai 0.4054651081081644\n",
      "natural_language_processing.txt : learning 0.0\n",
      "natural_language_processing.txt : machine 0.0\n",
      "natural_language_processing.txt : networks 0.6931471805599453\n",
      "natural_language_processing.txt : neural 0.4054651081081644\n",
      "artificial_intelligence.txt : ai 0.4054651081081644\n",
      "artificial_intelligence.txt : learning 0.0\n",
      "artificial_intelligence.txt : machine 0.0\n",
      "artificial_intelligence.txt : networks 0.6931471805599453\n",
      "artificial_intelligence.txt : neural 0.4054651081081644\n",
      "neural_network.txt : ai 0.4054651081081644\n",
      "neural_network.txt : learning 0.0\n",
      "neural_network.txt : machine 0.0\n",
      "neural_network.txt : networks 0.6931471805599453\n",
      "neural_network.txt : neural 0.4054651081081644\n",
      "machine_learning.txt : ai 0.4054651081081644\n",
      "machine_learning.txt : learning 0.0\n",
      "machine_learning.txt : machine 0.0\n",
      "machine_learning.txt : networks 0.6931471805599453\n",
      "machine_learning.txt : neural 0.4054651081081644\n"
     ]
    }
   ],
   "source": [
    "# Bring everything together.\n",
    "query = \"machine learning ai neural networks\"\n",
    "set_query = set(tokenize(query))\n",
    "\n",
    "# Dict for tf-idf\n",
    "tf_idf = {}\n",
    "\n",
    "# First loop over all files.\n",
    "for file in file_words.keys():\n",
    "    \n",
    "    list_compute_current_file = []\n",
    "    # Loop over words in set query.\n",
    "    for word in set_query:\n",
    "        \n",
    "        # if word in file_idfs and file_idfs[word] != 0:\n",
    "            print(file, \":\", word,  file_idfs[word])\n",
    "            list_compute_current_file.append(file_idfs[word] * file_words[file].count(word))\n",
    "    \n",
    "    # print(list_compute_current_file)\n",
    "    \n",
    "    # Compute tf-idf and save in dict.\n",
    "    tf_idf[file] = sum(list_compute_current_file)\n",
    "    # print(tf_idf)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'probability.txt': 0.0,\n",
       " 'python.txt': 0.8109302162163288,\n",
       " 'natural_language_processing.txt': 2.027325540540822,\n",
       " 'artificial_intelligence.txt': 134.1797605846713,\n",
       " 'neural_network.txt': 45.73625101595245,\n",
       " 'machine_learning.txt': 18.04892876131529}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('artificial_intelligence.txt', 134.1797605846713),\n",
       " ('neural_network.txt', 45.73625101595245),\n",
       " ('machine_learning.txt', 18.04892876131529),\n",
       " ('natural_language_processing.txt', 2.027325540540822),\n",
       " ('python.txt', 0.8109302162163288),\n",
       " ('probability.txt', 0.0)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(tf_idf.items(), key= lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return ordered list with file names with best match first (desc).\n",
    "list_matching_files = []\n",
    "tf_idf_sorted = sorted(tf_idf.items(), key= lambda x:x[1], reverse=True)\n",
    "\n",
    "n = 6\n",
    "\n",
    "i = 0\n",
    "while i < n:\n",
    "    list_matching_files.append(tf_idf_sorted[i][0])\n",
    "    i += 1\n",
    "\n",
    "print(list_matching_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_files_(query, files, idfs, n):\n",
    "    \n",
    "    set_query = set(tokenize(query))\n",
    "    tf_idf = {}\n",
    "    \n",
    "    # First loop over all files.\n",
    "    for file in files.keys():\n",
    "        list_compute_current_file = []\n",
    "        # Loop over words in set query.\n",
    "        for word in set_query:\n",
    "            if word in idfs and idfs[word] != 0:\n",
    "                list_compute_current_file.append(idfs[word] * files[file].count(word))\n",
    "\n",
    "        # Compute tf-idf and save in dict.\n",
    "        tf_idf[file] = sum(list_compute_current_file)\n",
    "    \n",
    "    # Return ordered list with file names with best match first (desc).\n",
    "    list_ordered_files = []\n",
    "    tf_idf_sorted = sorted(tf_idf.items(), key= lambda x:x[1], reverse=True)\n",
    "    \n",
    "    i = 0\n",
    "    while i < n:\n",
    "        list_ordered_files.append(tf_idf_sorted[i][0])\n",
    "        i += 1\n",
    "    \n",
    "    return list_ordered_files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = load_files(\"./corpus/\") # Load file into memory as string.\n",
    "file_words = {\n",
    "    filename: tokenize(files[filename]) # Tokenize into list of words.\n",
    "    for filename in files\n",
    "}\n",
    "file_idfs = compute_idfs(file_words) # Compute inverse document frequency values for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is python and when was ist founded?\"\n",
    "top_files_(query, file_words, file_idfs, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from questions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = load_files(\"./corpus/\") # Load file into memory as string.\n",
    "file_words = {\n",
    "    filename: tokenize(files[filename]) # Tokenize into list of words.\n",
    "    for filename in files\n",
    "}\n",
    "file_idfs = compute_idfs(file_words) # Compute inverse document frequency values for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"When was machine learning founded and what is a neural network?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neural_network.txt', 'artificial_intelligence.txt']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_files(query, file_words, file_idfs, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51aac96a1ad50adc7d4a1a596256386b3ce94cd59070594d461c13d85ed1cee1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
